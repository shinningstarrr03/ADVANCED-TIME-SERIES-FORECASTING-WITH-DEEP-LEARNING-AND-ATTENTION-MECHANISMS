# -*- coding: utf-8 -*-
"""Advanced Dl project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19nbanVXRBcPbnZjhpv2H7oH-qrLk_esh
"""

# Full runnable Colab-ready script (copy-paste)
# Requires: tensorflow, statsmodels, scikit-learn, matplotlib, pandas, numpy
# (In Colab: you may need to pip install statsmodels / pmdarima)
# e.g. `!pip install statsmodels pmdarima` if needed.

import os
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# ---------------------------
# Utilities
# ---------------------------
def mape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    denom = np.where(np.abs(y_true) < 1e-8, 1.0, np.abs(y_true))
    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0

def rmse(y_true, y_pred):
    return math.sqrt(mean_squared_error(y_true, y_pred))

# ---------------------------
# Data: synthetic multivariate time series (replace with your CSV if needed)
# ---------------------------
def create_synthetic_multivariate(n_steps=1200, seed=42):
    np.random.seed(seed)
    t = np.arange(n_steps)
    trend = 0.01 * t
    seasonal = 5.0 * np.sin(2 * np.pi * t / 24.0)
    seasonal2 = 2.0 * np.sin(2 * np.pi * t / 168.0)
    noise = np.random.normal(scale=0.5, size=n_steps)
    target = 10 + trend + seasonal + seasonal2 + noise

    feature1 = 20 + 3.0 * np.sin(2 * np.pi * (t + 3) / 24.0) + np.random.normal(0, 0.4, n_steps)
    feature2 = ((t % 168) < 24).astype(float)
    feature3 = np.random.normal(0, 1, n_steps)

    df = pd.DataFrame({
        'target': target,
        'temp': feature1,
        'holiday_flag': feature2,
        'sensor': feature3
    }, index=pd.RangeIndex(start=0, stop=n_steps, name='time'))
    return df

df = create_synthetic_multivariate(n_steps=1200)
print("Data shape:", df.shape)
print(df.head())

# ---------------------------
# Preprocessing and sliding-window creation
# ---------------------------
plt.figure(figsize=(10,3))
plt.plot(df['target'])
plt.title('Synthetic target series')
plt.show()

# scaling
scaler = MinMaxScaler()
scaled = scaler.fit_transform(df.values)
scaled_df = pd.DataFrame(scaled, columns=df.columns, index=df.index)

# sliding window
def make_dataset(data_df, target_col='target', enc_len=48, dec_len=24, step=1):
    X_enc, y_dec = [], []
    values = data_df.values
    n = len(data_df)
    target_idx = data_df.columns.get_loc(target_col)
    for start in range(0, n - enc_len - dec_len + 1, step):
        enc_slice = values[start:start+enc_len, :]
        dec_slice = values[start+enc_len:start+enc_len+dec_len, target_idx]
        X_enc.append(enc_slice)
        y_dec.append(dec_slice.reshape(-1, 1))
    return np.array(X_enc), np.array(y_dec)

ENC_LEN = 48
DEC_LEN = 24
STEP = 1

X_enc, y_dec = make_dataset(scaled_df, 'target', ENC_LEN, DEC_LEN, STEP)
print("X_enc shape:", X_enc.shape, "y_dec shape:", y_dec.shape)

# splits
n_samples = X_enc.shape[0]
train_end = int(n_samples * 0.7)
val_end = int(n_samples * 0.85)

X_train, y_train = X_enc[:train_end], y_dec[:train_end]
X_val, y_val     = X_enc[train_end:val_end], y_dec[train_end:val_end]
X_test, y_test   = X_enc[val_end:], y_dec[val_end:]

print("Splits:", X_train.shape, X_val.shape, X_test.shape)

# ---------------------------
# Baseline: persistence (last value of encoder target) per test sample
# ---------------------------
def persistence_baseline(df_raw_target, enc_len, dec_len, n_samples_total, test_sample_start_index):
    """
    df_raw_target: original target array (not scaled)
    enc_len, dec_len: window lengths
    n_samples_total: total number of sliding samples (X_enc length)
    test_sample_start_index: starting sample index in X_enc for test set
    returns: numpy array shaped (n_test_samples, dec_len)
    """
    forecasts = []
    # number of test samples
    n_test_samples = n_samples_total - test_sample_start_index
    for sample_idx in range(test_sample_start_index, test_sample_start_index + n_test_samples):
        # in our generation, sample i's encoder covers raw times [i ... i+enc_len-1]
        enc_end_time = sample_idx + enc_len
        last_val = df_raw_target[enc_end_time - 1]
        forecasts.append(np.full((dec_len,), last_val))
    return np.array(forecasts)

baseline_forecasts = persistence_baseline(df['target'].values, ENC_LEN, DEC_LEN, n_samples, val_end)
print("Baseline forecasts shape:", baseline_forecasts.shape, "y_test shape:", y_test.shape)

# Build y_test in original units for evaluation
y_test_orig = []
for i_sample in range(val_end, val_end + len(y_test)):
    enc_end_time = i_sample + ENC_LEN
    future_slice = df['target'].values[enc_end_time:enc_end_time+DEC_LEN]
    y_test_orig.append(future_slice)
y_test_orig = np.array(y_test_orig)
print("y_test_orig shape:", y_test_orig.shape)

baseline_mae = mean_absolute_error(y_test_orig.flatten(), baseline_forecasts.flatten())
baseline_rmse = rmse(y_test_orig.flatten(), baseline_forecasts.flatten())
baseline_mape = mape(y_test_orig.flatten(), baseline_forecasts.flatten())
print(f"Baseline results — MAE: {baseline_mae:.4f}, RMSE: {baseline_rmse:.4f}, MAPE: {baseline_mape:.2f}%")

# ---------------------------
# Bahdanau Attention layer (reusable; we'll extract its weights later)
# ---------------------------
class BahdanauAttention(layers.Layer):
    def __init__(self, units, name='bahdanau_attention', **kwargs):
        super().__init__(name=name, **kwargs)
        self.units = units
        # Use Dense layers as in Keras (we can access their weights later)
        self.W1 = layers.Dense(units, use_bias=True, name=name + '_W1')
        self.W2 = layers.Dense(units, use_bias=True, name=name + '_W2')
        self.V  = layers.Dense(1, use_bias=True, name=name + '_V')

    def call(self, enc_out, dec_out):
        # enc_out: (batch, enc_len, enc_units)
        # dec_out: (batch, dec_len, dec_units)
        # project
        # enc_proj -> (batch, enc_len, units)
        enc_proj = self.W1(enc_out)
        # dec_proj -> (batch, dec_len, units)
        dec_proj = self.W2(dec_out)
        # We want scores for each (enc_time, dec_time)
        # Expand dims and add -> (batch, enc_len, dec_len, units)
        enc_exp = tf.expand_dims(enc_proj, 2)   # (batch, enc_len, 1, units)
        dec_exp = tf.expand_dims(dec_proj, 1)   # (batch, 1, dec_len, units)
        score_raw = self.V(tf.nn.tanh(enc_exp + dec_exp))  # (batch, enc_len, dec_len, 1)
        score_raw = tf.squeeze(score_raw, axis=-1)  # (batch, enc_len, dec_len)
        # transpose so decoder-time first: (batch, dec_len, enc_len)
        score = tf.transpose(score_raw, perm=[0, 2, 1])
        attention_weights = tf.nn.softmax(score, axis=-1)  # softmax over encoder timesteps
        # context: for each dec step, weighted sum over enc outputs -> (batch, dec_len, enc_units)
        context = tf.matmul(attention_weights, enc_out)
        return context, attention_weights

# ---------------------------
# Build encoder-decoder with attention
# ---------------------------
def build_lstm_attention_model(enc_len, dec_len, n_features, enc_units=64, dec_units=64, attn_units=48, lr=1e-3):
    encoder_inputs = Input(shape=(enc_len, n_features), name='encoder_inputs')
    encoder_lstm = layers.LSTM(enc_units, return_sequences=True, return_state=True, name='encoder_lstm')
    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)

    decoder_inputs = Input(shape=(dec_len, 1), name='decoder_inputs')
    decoder_lstm = layers.LSTM(dec_units, return_sequences=True, return_state=True, name='decoder_lstm')
    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])

    attention_layer = BahdanauAttention(attn_units, name='bahdanau_attention')
    context_seq, attn_weights = attention_layer(encoder_outputs, decoder_outputs)

    concat = layers.Concatenate(axis=-1)([context_seq, decoder_outputs])
    dense_time = layers.TimeDistributed(layers.Dense(64, activation='relu'))(concat)
    output_time = layers.TimeDistributed(layers.Dense(1), name='decoder_output')(dense_time)

    model = Model([encoder_inputs, decoder_inputs], output_time)
    model.compile(optimizer=Adam(learning_rate=lr), loss='mse', metrics=['mae'])
    return model

n_features = X_train.shape[2]
model = build_lstm_attention_model(ENC_LEN, DEC_LEN, n_features, enc_units=64, dec_units=64, attn_units=48, lr=1e-3)
model.summary()

# ---------------------------
# Train (decoder inputs are zeros during training as reasonable teacher forcing placeholder)
# ---------------------------
def get_decoder_inputs(y, dec_len):
    return np.zeros_like(y)

decoder_train = get_decoder_inputs(y_train, DEC_LEN)
decoder_val   = get_decoder_inputs(y_val, DEC_LEN)
decoder_test  = get_decoder_inputs(y_test, DEC_LEN)

es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
history = model.fit([X_train, decoder_train], y_train,
                    validation_data=([X_val, decoder_val], y_val),
                    epochs=80, batch_size=32, callbacks=[es], verbose=2)

plt.figure(figsize=(7,3))
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.title('Loss curves')
plt.show()

# ---------------------------
# Predict on test set and evaluate
# ---------------------------
preds_scaled = model.predict([X_test, decoder_test])  # shape (n_test, dec_len, 1)
print("Preds_scaled shape:", preds_scaled.shape)

# inverse scale target using scaler min/max for target column
target_col_index = df.columns.get_loc('target')
data_min = scaler.data_min_[target_col_index]
data_max = scaler.data_max_[target_col_index]
def invert_scaled_target(scaled_arr):
    return scaled_arr.squeeze(-1) * (data_max - data_min) + data_min

preds_orig = invert_scaled_target(preds_scaled)
y_test_orig_from_scaled = invert_scaled_target(y_test)

model_mae = mean_absolute_error(y_test_orig_from_scaled.flatten(), preds_orig.flatten())
model_rmse = rmse(y_test_orig_from_scaled.flatten(), preds_orig.flatten())
model_mape = mape(y_test_orig_from_scaled.flatten(), preds_orig.flatten())
print(f"Attention model results — MAE: {model_mae:.4f}, RMSE: {model_rmse:.4f}, MAPE: {model_mape:.2f}%")
print(f"Baseline results — MAE: {baseline_mae:.4f}, RMSE: {baseline_rmse:.4f}, MAPE: {baseline_mape:.2f}%")

# ---------------------------
# Extract exact Bahdanau attention weights (correct numeric extraction using trained layer weights)
# For a single test example (test_i), we compute enc_out and dec_out via a Keras submodel and then apply
# the attention layer's learned weights in NumPy to compute exact scores and softmax.
# ---------------------------
test_i = 5  # choose a test-index from 0 .. len(X_test)-1
x_enc_ex = X_test[test_i:test_i+1]     # (1, enc_len, n_features)
dec_in_ex = np.zeros((1, DEC_LEN, 1))

# Build submodel that gives encoder sequence outputs and decoder sequence outputs (using same layers)
encoder_layer = model.get_layer('encoder_lstm')
decoder_layer = model.get_layer('decoder_lstm')

# Recompute the encoder and decoder intermediate tensors from model inputs
enc_out_tensor, enc_h, enc_c = encoder_layer(model.input[0])
dec_out_tensor = decoder_layer(model.input[1], initial_state=[enc_h, enc_c])[0]

submodel = Model(inputs=model.inputs, outputs=[enc_out_tensor, dec_out_tensor])
enc_out_val, dec_out_val = submodel.predict([x_enc_ex, dec_in_ex])
enc_out_val = np.asarray(enc_out_val)   # (1, enc_len, enc_units)
dec_out_val = np.asarray(dec_out_val)   # (1, dec_len, dec_units)
print("encoder outputs shape:", enc_out_val.shape)
print("decoder outputs shape:", dec_out_val.shape)

# Get attention layer and its internal Dense weights
att_layer = model.get_layer('bahdanau_attention')
W1_w, W1_b = att_layer.W1.get_weights()  # shapes: (enc_units, units), (units,)
W2_w, W2_b = att_layer.W2.get_weights()  # shapes: (dec_units, units), (units,)
V_w,  V_b  = att_layer.V.get_weights()   # shapes: (units, 1), (1,)

# NumPy computation of exact attention scores used in call()
# enc_proj = enc_out @ W1 + b1  -> (1, enc_len, units)
enc_proj = np.tensordot(enc_out_val, W1_w, axes=([2],[0])) + W1_b  # (1, enc_len, units)
# dec_proj = dec_out @ W2 + b2 -> (1, dec_len, units)
dec_proj = np.tensordot(dec_out_val, W2_w, axes=([2],[0])) + W2_b  # (1, dec_len, units)

# Expand dims & add: (1, enc_len, dec_len, units)
enc_exp = np.expand_dims(enc_proj, axis=2)  # (1, enc_len, 1, units)
dec_exp = np.expand_dims(dec_proj, axis=1)  # (1, 1, dec_len, units)
sum_proj = np.tanh(enc_exp + dec_exp)        # (1, enc_len, dec_len, units)

# Multiply by V: score_raw = sum_proj @ V_w + V_b -> (1, enc_len, dec_len, 1) -> squeeze -> (1, enc_len, dec_len)
score_raw = np.tensordot(sum_proj, V_w, axes=([3],[0])) + V_b  # (1, enc_len, dec_len, 1)
score_raw = np.squeeze(score_raw, axis=-1)  # (1, enc_len, dec_len)

# transpose to (1, dec_len, enc_len) to match attention call
score_transposed = np.transpose(score_raw, (0, 2, 1))  # (1, dec_len, enc_len)

# softmax over encoder axis -> attention weights
attn_weights_exact = tf.nn.softmax(score_transposed, axis=-1).numpy()  # (1, dec_len, enc_len)
attn_weights_for_plot = attn_weights_exact[0]
print("Attention exact shape:", attn_weights_for_plot.shape)

# ---------------------------
# Plot example: past + actual + prediction
# ---------------------------
pred_ex = preds_orig[test_i]  # predicted future (DEC_LEN,)
past_target_orig = x_enc_ex[0,:,target_col_index] * (data_max - data_min) + data_min

plt.figure(figsize=(10,4))
plt.plot(range(ENC_LEN), past_target_orig, label='past target (orig units)')
plt.plot(range(ENC_LEN, ENC_LEN+DEC_LEN), y_test_orig_from_scaled[test_i], label='actual future')
plt.plot(range(ENC_LEN, ENC_LEN+DEC_LEN), pred_ex, label='predicted future')
plt.axvline(x=ENC_LEN-0.5, linestyle='--', color='gray')
plt.legend()
plt.title('Past + actual future + predicted future (example)')
plt.show()

# Attention heatmap
plt.figure(figsize=(10,5))
plt.imshow(attn_weights_for_plot, aspect='auto')
plt.colorbar(label='attention weight')
plt.xlabel('encoder timestep (past index)')
plt.ylabel('decoder timestep (future step)')
plt.title('Exact Bahdanau attention weights (decoder t rows, encoder t cols)')
plt.show()

# Textual interpretation (top-3 encoder timesteps per future step)
def interpret_attention_exact(attn_matrix, top_k=3):
    dec_len, enc_len = attn_matrix.shape
    lines = []
    for j in range(dec_len):
        row = attn_matrix[j]
        top_idxs = np.argsort(row)[-top_k:][::-1]
        # relative indices from encoder end
        rel_idxs = [idx - (enc_len-1) for idx in top_idxs]
        lines.append(f"Future t+{j+1}: encoder indices {top_idxs.tolist()} (relative to end: {rel_idxs})")
    return "\n".join(lines)

print("Attention interpretation (exact):\n", interpret_attention_exact(attn_weights_for_plot, top_k=3))

# ---------------------------
# Save model and results
# ---------------------------
results_summary = pd.DataFrame({
    'model': ['Baseline (persistence)', 'LSTM + Bahdanau Attention'],
    'MAE': [baseline_mae, model_mae],
    'RMSE': [baseline_rmse, model_rmse],
    'MAPE (%)': [baseline_mape, model_mape]
})
print("\nResults summary:\n", results_summary)

model.save('lstm_bahdanau_attention_model.h5')
results_summary.to_csv('results_summary.csv', index=False)
print("Saved model -> lstm_bahdanau_attention_model.h5")
print("Saved summary -> results_summary.csv")